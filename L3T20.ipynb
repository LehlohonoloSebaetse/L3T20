{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-31T11:07:03.075845Z","iopub.execute_input":"2022-08-31T11:07:03.076291Z","iopub.status.idle":"2022-08-31T11:07:03.099701Z","shell.execute_reply.started":"2022-08-31T11:07:03.076184Z","shell.execute_reply":"2022-08-31T11:07:03.098062Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Import the necessary libraries\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nimport numpy as np\nimport re\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import LSTM, Dropout, Dense, Embedding, SpatialDropout1D, BatchNormalization\n\n# from tensorflow.keras.layers.normalization import BatchNormalization\n\n\nimport wordcloud\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:03.101828Z","iopub.execute_input":"2022-08-31T11:07:03.102409Z","iopub.status.idle":"2022-08-31T11:07:05.455146Z","shell.execute_reply.started":"2022-08-31T11:07:03.102357Z","shell.execute_reply":"2022-08-31T11:07:05.453979Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Make results reproducible - set random seed\nfrom numpy.random import seed\nseed(42)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:05.456657Z","iopub.execute_input":"2022-08-31T11:07:05.456925Z","iopub.status.idle":"2022-08-31T11:07:05.461428Z","shell.execute_reply.started":"2022-08-31T11:07:05.456892Z","shell.execute_reply":"2022-08-31T11:07:05.460384Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"negative_file = \"/kaggle/input/movie-book-review/negative.txt\"\npositive_file = \"/kaggle/input/movie-book-review/positive.txt\"","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:05.463025Z","iopub.execute_input":"2022-08-31T11:07:05.463383Z","iopub.status.idle":"2022-08-31T11:07:05.476003Z","shell.execute_reply.started":"2022-08-31T11:07:05.463332Z","shell.execute_reply":"2022-08-31T11:07:05.475190Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Do not modify - helper function to load and preprocess data\ndef filter_words(line):    \n    line = re.sub(r'[^\\w\\s]','',line.rstrip())\n    words = line.split(\" \") \n    words = [i.lower() for i in words if i]      \n    return \" \".join(words)\n\ndef load_data(filename):\n    thefile = open(filename, 'r') \n    lines = thefile.readlines() \n\n    data = []\n    for l in range(0,len(lines)): \n        if(lines[l-1].strip() == \"<title>\"): \n            theline = filter_words(lines[l])\n            if(len(theline) < 50):\n                data.append(theline)            \n            \n    return data\n\n# Helper function to convert categorical data to class label\ndef to_word_label(y):\n    y = to_class(y)   \n    return [\"positive\" if i==0 else \"negative\" for i in y]\n\n# Helper function to convert class label to numeric label\ndef to_numeric_label(y):\n  return [0 if i==\"positive\" else 1 for i in word_labels]\n\n# Helper function: this function needs to be called before sending arrays to sklearn metrics,\n# it converts back to class form from categorical form. ie: [1,0] --> 0, [0,1] --> 1\ndef to_class(y):\n    return np.argmax(y,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:05.478178Z","iopub.execute_input":"2022-08-31T11:07:05.478777Z","iopub.status.idle":"2022-08-31T11:07:05.489747Z","shell.execute_reply.started":"2022-08-31T11:07:05.478742Z","shell.execute_reply":"2022-08-31T11:07:05.488900Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"positive = load_data(positive_file)\nnegative = load_data(negative_file)\n\n#to view the first 10 positive review text and first 10 negative reviews\nprint(positive[0:10])\nprint(\"\\n\")\nprint(negative[0:10])","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:05.491092Z","iopub.execute_input":"2022-08-31T11:07:05.491372Z","iopub.status.idle":"2022-08-31T11:07:05.546736Z","shell.execute_reply.started":"2022-08-31T11:07:05.491341Z","shell.execute_reply":"2022-08-31T11:07:05.545552Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Do not modify - Combines the positive and negative reviews into a single list and create labels\ndata = positive + negative\nword_labels = [\"positive\"] * len(positive) + [\"negative\"] * len(negative) \n\n# Converts labels to numbers in one-hot encoding - [1, 0] (positive) or [0, 1] (negative)\n# from keras.utils import to_categorical\nfrom tensorflow.keras.utils import to_categorical\nlabels  = to_categorical(to_numeric_label(word_labels))\nprint(type(data))","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:05.548612Z","iopub.execute_input":"2022-08-31T11:07:05.548880Z","iopub.status.idle":"2022-08-31T11:07:05.556430Z","shell.execute_reply.started":"2022-08-31T11:07:05.548848Z","shell.execute_reply":"2022-08-31T11:07:05.555519Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Write some code to investigate the dataset. \n# - Calculate and report the mean review size, its standard deviation and create a boxplot.\n\n#already loaded the matplotlib libraries at the top\n\ncount_words = []\ncount = 0\n\nfor i in data:\n    word_list = i.split()\n    number_of_words = len(word_list)\n    count_words.append(number_of_words)\n#     count_words += number_of_words\n    count += 1\n\n#Adding the words together\nadd = sum(count_words)\navg = add/count\nprint('The mean review word size is : {:.1f}'.format(avg))\n\nstd = np.std(count_words)\nprint(\"The standard deviation is calculated to: {:.1f}\".format(std))\n\nplt.boxplot(count_words)\nplt.grid()\nplt.show()\n\n# - Calculate the number of unique words in the dataset\n\n# A set is a collection in which all elements are unique.\nunique_words = set(data)\n\nunique_word_count = len(unique_words)\n# display the number of unique words \nprint(\"The number of unique words was calculated to be: {}\".format(unique_word_count))\n\n# - Perform any other dataset investigation that you feel would be valuable\n\n#plot a wordcloud of positive and negative book reviews  \n\nfrom wordcloud import WordCloud \n\nwordcloud = WordCloud(width = 1000, height = 500).generate(\" \".join(data))\nprint(\"WORD CLOUD DIAGRAM\")\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.savefig(\"your_file_name\"+\".png\", bbox_inches='tight')\nplt.show()\nplt.close()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:05.558028Z","iopub.execute_input":"2022-08-31T11:07:05.558649Z","iopub.status.idle":"2022-08-31T11:07:07.655609Z","shell.execute_reply.started":"2022-08-31T11:07:05.558604Z","shell.execute_reply":"2022-08-31T11:07:07.654699Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### The word cloud above displays some of the most frequent words found in the dataset.","metadata":{}},{"cell_type":"code","source":"# Do not modify - Tokenize the vocabulary \nfrom keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=25)\n\ntokenizer.fit_on_texts(data) #create the vocabularry\n\ntokenized_data = tokenizer.texts_to_sequences(data) #tokenize the data using the vocabulary\n\nvocab_size = len(tokenizer.word_index) + 1 \n\n# Compare a sample of the data before and after tokenization\nprint(data[0:5])\nprint(tokenized_data[0:5])\n#display the length of the tokenized data\nprint(len(tokenized_data))","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:07.657055Z","iopub.execute_input":"2022-08-31T11:07:07.657816Z","iopub.status.idle":"2022-08-31T11:07:07.712577Z","shell.execute_reply.started":"2022-08-31T11:07:07.657769Z","shell.execute_reply":"2022-08-31T11:07:07.711934Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing","metadata":{}},{"cell_type":"code","source":"# Pre-processing\n# Write some code to pre-process the data so that each review is the same length\n# Put the padding at the end of the sequences\n\npadded = pad_sequences(tokenized_data, maxlen = 4, padding = \"post\")\n\n#display the first five padded sequence\nprint(\"Padded tokenized_data:\\n {}\".format(padded[ :5]))","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:07.713547Z","iopub.execute_input":"2022-08-31T11:07:07.714213Z","iopub.status.idle":"2022-08-31T11:07:07.733192Z","shell.execute_reply.started":"2022-08-31T11:07:07.714176Z","shell.execute_reply":"2022-08-31T11:07:07.732179Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Write some code to split the data into a training and test set. Make sure you shuffle the data. Use 20% for the test set.\ny = labels\nX = padded\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 42)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:07.734584Z","iopub.execute_input":"2022-08-31T11:07:07.734990Z","iopub.status.idle":"2022-08-31T11:07:07.746997Z","shell.execute_reply.started":"2022-08-31T11:07:07.734944Z","shell.execute_reply":"2022-08-31T11:07:07.745944Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\nfrom sklearn.metrics import accuracy_score\n\n# Fill in the following function so it\n# - makes a prediction for the test set given the model\n# - reports the precision, recall and f1 score. Also print the confusion matrix. \n# You will need to use the helper to_class function to convert y_pred and y_test before supplying them to the sklearn functions.\n\ndef assess_model(model, X_test, y_test):\n    \n    # use the helper to_class function to convert\n    # y_pred and y_test before supplying them to the sklearn functions.\n    y_test = to_class(y_test)\n    \n    #Get the predictions for y_pred\n    #makes a prediction for the test set given the model\n    y_pred = model.predict(X_test)\n       \n    # Calculate the confusion matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n\n    #Evaluate precision_score\n    print()\n    print(precision_score(y_test, y_pred))\n    #Display the recall_score\n    print()\n    print(recall_score(y_test, y_pred))\n    #Display the f1_score\n    print(f1_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:07.748117Z","iopub.execute_input":"2022-08-31T11:07:07.748967Z","iopub.status.idle":"2022-08-31T11:07:07.760096Z","shell.execute_reply.started":"2022-08-31T11:07:07.748928Z","shell.execute_reply":"2022-08-31T11:07:07.759194Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Build and tune model","metadata":{}},{"cell_type":"markdown","source":"Define network architecture","metadata":{}},{"cell_type":"code","source":"# initializing an object from TensorFlow’s Sequential class\n# Build the sequencial model of recurrent neural network (RNN)\nmodel = Sequential()\n\n# output_dim can be any value\n# output_dim is defined as the number of dimensions we wish to embed into\n#creating and adding the embedding layer\nembedding_layer = Embedding(input_dim = 1794, output_dim = 32, input_length = 4)\nmodel.add(embedding_layer)\n\n\n# adding SpatialDropout1D(0.2) layer\nmodel.add(SpatialDropout1D(0.2))\n\n# BatchNormalization()\nBatchNormalization()\n\n# add an lstm layer of 32\nmodel.add(LSTM(32))\n\n# adding a dense layer\nmodel.add(Dense(2, activation = 'softmax'))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:07.761600Z","iopub.execute_input":"2022-08-31T11:07:07.762110Z","iopub.status.idle":"2022-08-31T11:07:08.062785Z","shell.execute_reply.started":"2022-08-31T11:07:07.762056Z","shell.execute_reply":"2022-08-31T11:07:08.061782Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Train model\n#### TRAIN AND TUNE THE MODEL","metadata":{}},{"cell_type":"code","source":"# Compiling our neural network\n# The compilation step of building a neural network is where we specify the neural net’s optimizer and loss function.\n# model.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n\n# Fitting The Recurrent Neural Network On The Training Set\n# Will specify epochs = 100 in this case.\n# the size of batches (32) that the network will be trained in through each epoch.\n# model.fit(X_train, y_train, output_dim = 10, epochs = 5, batch_size = 10)\n\n# Defining the model\n\n# function to determine the best output_dim\n# creating an empty list\nempty_list = []\n\nlst = [10, 25, 50, 100]\nfor i in lst:\n    \n    # Initialize the classifier\n    model = Sequential()\n#     adding layers to the model\n    embedding_layer = Embedding(input_dim = 1794, output_dim = i, input_length = 4)\n    model.add(embedding_layer)\n    model.add(SpatialDropout1D(0.3))\n    BatchNormalization()\n    model.add(LSTM(32))\n    model.add(Dense(2, activation = 'softmax'))\n    model.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n    history = model.fit(X_train, y_train, epochs = 5, batch_size = 10, validation_steps = 30)\n    model.summary()\n    \n    empty_list.append(model)\n    \n\nloss_value_model = empty_list[0] \n\nfor model_loss in empty_list:\n    \n    if loss_value_model.loss > model_loss.loss:\n        \n        loss_value_model = model_loss\n        \n\nprint(\"\\n\\n\\n\")        \nloss_value_model.summary()    \n    \n    \n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:08.065768Z","iopub.execute_input":"2022-08-31T11:07:08.066047Z","iopub.status.idle":"2022-08-31T11:07:34.202561Z","shell.execute_reply.started":"2022-08-31T11:07:08.066007Z","shell.execute_reply":"2022-08-31T11:07:34.201654Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Examine performance of model","metadata":{}},{"cell_type":"markdown","source":"Plot graphs for accuracy and loss","metadata":{}},{"cell_type":"code","source":"# Plot the loss_per_epoch\nloss_per_epoch = model.history.history['loss']\nplt.plot(range(len(loss_per_epoch)), loss_per_epoch)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:34.206209Z","iopub.execute_input":"2022-08-31T11:07:34.206465Z","iopub.status.idle":"2022-08-31T11:07:34.435622Z","shell.execute_reply.started":"2022-08-31T11:07:34.206422Z","shell.execute_reply":"2022-08-31T11:07:34.434727Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# calling the assess_model function\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:34.436669Z","iopub.execute_input":"2022-08-31T11:07:34.436905Z","iopub.status.idle":"2022-08-31T11:07:34.441465Z","shell.execute_reply.started":"2022-08-31T11:07:34.436877Z","shell.execute_reply":"2022-08-31T11:07:34.440562Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#display the first 10 model predictions\npredictins = model.predict(X_test)\npredictins[0:10]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:34.442970Z","iopub.execute_input":"2022-08-31T11:07:34.443805Z","iopub.status.idle":"2022-08-31T11:07:34.975481Z","shell.execute_reply.started":"2022-08-31T11:07:34.443758Z","shell.execute_reply":"2022-08-31T11:07:34.974787Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Make a prediction","metadata":{}},{"cell_type":"code","source":"# This is a very small set of completed new data to use to make predictions.\nprediction_data = [\"this book is fabulous\",\"i hated this book\", \"the best\", \"no good\", \"okay\"]\ntokenized = tokenizer.texts_to_sequences(prediction_data)\npadded = pad_sequences(tokenized, padding = 'post', maxlen = 4)\n\n# Supply this data to each of your models and see how it does. \n# You can call the helper function \"to_word_label\" to map the output of the model to the name of the\n# class it was predicted to belong to.\n\n#call filter_words function to load and preprocess data\n#maxlen was changed to 4 \n\n#display the predicted results of the model\nprint(to_word_label(padded))\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:07:34.976849Z","iopub.execute_input":"2022-08-31T11:07:34.977094Z","iopub.status.idle":"2022-08-31T11:07:34.986898Z","shell.execute_reply.started":"2022-08-31T11:07:34.977063Z","shell.execute_reply":"2022-08-31T11:07:34.986121Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# References\n\n[1] https://www.freecodecamp.org/news/the-ultimate-guide-to-recurrent-neural-networks-in-python7/\n\n[2] https://www.simplilearn.com/tutorials/deep-learning-tutorial/rnn\n\n[3] https://www.freecodecamp.org/news/the-ultimate-guide-to-recurrent-neural-networks-in-python/\n\n[4] https://python.tutorialink.com/generating-word-cloud-for-items-in-a-list-in-python/\n\n[5] https://www.youtube.com/watch?v=jC0jXsX-33Q\n\n[6] https://vitalflux.com/accuracy-precision-recall-f1-score-python-example/\n\n[7] https://www.youtube.com/watch?v=S8tpSG6Q2H0\n\n[8] https://towardsdatascience.com/step-by-step-guide-building-a-prediction-model-in-python-ac441e8b9e8b\n\n[9] https://www.nbshare.io/notebook/249468051/How-To-Code-RNN-and-LSTM-Neural-Networks-in-Python/","metadata":{}}]}